{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:37:28.247807Z",
     "start_time": "2024-05-22T20:37:24.463572Z"
    }
   },
   "source": [
    "import torch\n",
    "from models.UNet import UNet\n",
    "from data_prep.preprocess import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import Tensor\n",
    "from torch import optim\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:37:32.110788Z",
     "start_time": "2024-05-22T20:37:29.802198Z"
    }
   },
   "source": [
    "train_loader, test_loader = Preprocess().get_data_loaders(subset=True)\n",
    "\n",
    "input_height = 600\n",
    "input_width = 400\n",
    "input_features = 3\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:37:33.222270Z",
     "start_time": "2024-05-22T20:37:33.211842Z"
    }
   },
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:37:35.241377Z",
     "start_time": "2024-05-22T20:37:35.233243Z"
    }
   },
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:43:14.861082Z",
     "start_time": "2024-05-22T20:43:14.856001Z"
    }
   },
   "source": [
    "\n",
    "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert input.size() == target.size()\n",
    "    assert input.dim() == 3 or not reduce_batch_first\n",
    "\n",
    "    sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
    "\n",
    "    inter = 2 * (input * target).sum(dim=sum_dim)\n",
    "    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
    "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "\n",
    "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
    "    return dice.mean()\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    return dice_coeff(input.flatten(0, 1), target.flatten(0, 1), reduce_batch_first, epsilon)\n",
    "\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(input, target, reduce_batch_first=True)\n",
    "\n",
    "def compute_iou(mask_pred, target_mask):\n",
    "    mask_pred = mask_pred.squeeze(1)\n",
    "    mask_pred = (mask_pred > 0.5).float().bool()\n",
    "    true_mask = target_mask.bool()\n",
    "\n",
    "    intersection = (mask_pred & true_mask).float().sum((1, 2))\n",
    "    union = (mask_pred | true_mask).float().sum((1, 2))\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    \n",
    "    return iou.mean()\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T21:07:14.268041Z",
     "start_time": "2024-05-22T21:06:59.260044Z"
    }
   },
   "source": [
    "\n",
    "dir_img = Path('./data/imgs/')\n",
    "dir_mask = Path('./data/masks/')\n",
    "dir_checkpoint = Path('./checkpoints/')\n",
    "\n",
    "\n",
    "def train_model(model, epochs=5, learning_rate=1e-5, amp=False, weight_decay=1e-8, gradient_clipping=1.0,):\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        losses, accuracy = [], 0\n",
    "        \n",
    "        for images, true_mask in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device=device, memory_format=torch.channels_last)\n",
    "            true_mask = true_mask.to(device=device, dtype=torch.long)\n",
    "            pred_mask = model(images).to(device=device)\n",
    "            \n",
    "            print(f'pred_mask shape: {pred_mask.shape}')            \n",
    "            print(f'true_mask shape: {true_mask.shape}')\n",
    "            \n",
    "            loss = criterion(pred_mask, true_mask.squeeze(1))\n",
    "            loss += dice_loss(F.softmax(pred_mask, dim=1).float(), \n",
    "                              F.one_hot(true_mask.squeeze(1), model.n_classes).permute(0, 3, 1, 2).float(), \n",
    "                              multiclass=True)\n",
    "            \n",
    "            iou = compute_iou(pred_mask, true_mask)\n",
    "            accuracy += iou\n",
    "            \n",
    "            grad_scaler.scale(loss).backward()\n",
    "            grad_scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        print(f'Epoch: {epoch}, Loss: {losses[-1] / len(train_loader)}, Accuracy: {accuracy / len(train_loader)}')\n",
    "\n",
    "\n",
    "unet = UNet(n_channels=3, n_classes=1)\n",
    "unet = unet.to(device=device, memory_format=torch.channels_last)\n",
    "train_model(model=unet, epochs=1)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_mask shape: torch.Size([4, 1, 600, 400])\n",
      "true_mask shape: torch.Size([4, 1, 600, 400])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m unet \u001B[38;5;241m=\u001B[39m UNet(n_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, n_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     46\u001B[0m unet \u001B[38;5;241m=\u001B[39m unet\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice, memory_format\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mchannels_last)\n\u001B[1;32m---> 47\u001B[0m train_model(model\u001B[38;5;241m=\u001B[39munet, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[14], line 40\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, epochs, learning_rate, amp, weight_decay, gradient_clipping)\u001B[0m\n\u001B[0;32m     37\u001B[0m     grad_scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m     38\u001B[0m     grad_scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[1;32m---> 40\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlosses[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccuracy\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T13:10:40.412719Z",
     "start_time": "2024-05-22T13:10:40.383172Z"
    }
   },
   "source": [
    "for i, (image, mask) in enumerate(train_loader):\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 600, 400])\n",
      "torch.Size([4, 1, 600, 400])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:10:40.878161Z",
     "start_time": "2024-05-22T13:10:40.413724Z"
    }
   },
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    unet.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, masks in train_loader:  # Assuming your DataLoader is named train_loader\n",
    "        #inputs, labels = inputs.to(device), labels.to(device)\n",
    "        print(inputs.shape)\n",
    "        print(masks.shape)\n",
    "        masks = masks.squeeze(1)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # TODO: Softmax + One-hot encoding of the outputs maybe?\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Loss: {running_loss}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "torch.Size([4, 3, 600, 400])\n",
      "torch.Size([4, 1, 600, 400])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m masks \u001B[38;5;241m=\u001B[39m masks\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Zero the parameter gradients\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# TODO: Softmax + One-hot encoding of the outputs maybe?\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m     18\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tensor = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "tensor.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tensor.squeeze(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tensor"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
