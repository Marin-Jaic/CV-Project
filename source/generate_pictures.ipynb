{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_prep.preprocess import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        logits = F.softmax(x, dim=1)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=3, n_classes=3)\n",
    "mps_device = torch.device(\"cpu\")\n",
    "weights_file = 'C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q4\\\\Seminar-Computer-Vision-by-Deep-Learning\\\\model_3masks_whole_dataset'\n",
    "model.load_state_dict(torch.load(weights_file, map_location=torch.device('cpu')))\n",
    "model = model.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pq.ParquetDataset('C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q4\\\\Seminar-Computer-Vision-by-Deep-Learning\\\\data')\n",
    "\n",
    "table = dataset.read()\n",
    "df = table.to_pandas()\n",
    "idx = 14165\n",
    "image = Image.open(BytesIO(df.iloc[idx, 0]['bytes'])) # image\n",
    "mask = np.array(Image.open(BytesIO(df.iloc[idx, 1]['bytes']))).astype(np.float16) # mask\n",
    "#image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_image(image, mask):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    # ax[0].imshow(image.permute(0, 1, 2)[0])\n",
    "    # ax[0].imshow(image.permute(0, 1, 2)[0])\n",
    "    # ax[1].imshow(mask[2])\n",
    "    ax[0].imshow(image)\n",
    "    #ax[1].imshow(mask, cmap='gray')\n",
    "    ax[1].imshow(mask)\n",
    "    plt.show()\n",
    "#show_image(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "torch.Size([600, 400, 3]) torch.Size([600, 400, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36800/1766775213.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36800/2001622046.py\u001b[0m in \u001b[0;36mshow_image\u001b[1;34m(image, mask)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# ax[0].imshow(image.permute(0, 1, 2)[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# ax[1].imshow(mask[2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m#ax[1].imshow(mask, cmap='gray')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mjaic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mjaic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mjaic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5486\u001b[0m                               **kwargs)\n\u001b[0;32m   5487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5488\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5489\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mjaic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         if (self._A.dtype != np.uint8 and\n",
      "\u001b[1;32mc:\\Users\\mjaic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[1;34m(x, copy)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# If we have already made a copy, do the byteswap in place, else make a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mjaic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader, test_loader = Preprocess().get_data_loaders(mask_classes=3, use_simple_mask=False, batch_size=1, subset_size=1)\n",
    "\n",
    "for inputs, labels in train_loader:\n",
    "    inputs, labels = inputs.to(mps_device), labels.to(mps_device)\n",
    "    outputs = model(inputs)\n",
    "    inputs = inputs.detach()\n",
    "    outputs = outputs.detach()\n",
    "    print(\"here\")\n",
    "    img = outputs[0].permute(1, 2, 0)\n",
    "    img2 = inputs[0].permute(1, 2, 0)\n",
    "    print(img.shape, img2.shape)\n",
    "    show_image(img, img2)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
